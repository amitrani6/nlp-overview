{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Alex/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Import the relevand section of the NLP library\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "import re\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seinfeld_directory = 'Seinfeld_Episodes/Season_5/'\n",
    "\n",
    "seinfeld_season_5_episodes = ['S05_E01_The_Mango.txt', 'S05_E02_The_Puffy_Shirt.txt',\n",
    "                              'S05_E03_The_Glasses.txt', 'S05_E04_The_Sniffing_Accountant.txt',\n",
    "                              'S05_E05_The_Bris.txt', 'S05_E06_The_Lip_Reader.txt',\n",
    "                              'S05_E07_The_Non_Fat_Yogurt.txt', 'S05_E08_The_Barber.txt',\n",
    "                              'S05_E09_The_Masseuse.txt', 'S05_E10_The_Cigar_Store_Indian.txt',\n",
    "                              'S05_E11_The_Conversion.txt', 'S05_E12_The_Stall.txt',\n",
    "                              'S05_E13_The_Dinner_Party.txt', 'S05_E14_The_Marine_Biologist.txt',\n",
    "                              'S05_E15_The_Pie.txt', 'S05_E16_The_Stand-In.txt',\n",
    "                              'S05_E17_The_Wife.txt', 'S05_E18_The_Raincoats_Part_1.txt',\n",
    "                              'S05_E19_The_Raincoats_Part_2.txt', 'S05_E20_The_Fire.txt',\n",
    "                              'S05_E21_The_Hamptons.txt', 'S05_E22_The Opposite.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def open_file(file_name):\n",
    "\n",
    "    with open(seinfeld_directory + file_name, 'r') as file:\n",
    "        raw_text = file.read().replace('\\n', ' ')\n",
    "    \n",
    "    return raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text_episode_2 = open_file(seinfeld_season_5_episodes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cleaned_episode(raw_text):\n",
    "    \n",
    "#     raw_text_no_notes = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", raw_text)\n",
    "\n",
    "#     for symbol in \",.?!''\\n\":\n",
    "#         cleaned_text = raw_text_no_notes.replace(symbol, \"\").lower()\n",
    "\n",
    "#     cleaned_text = cleaned_text.split(\" \")    \n",
    "    \n",
    "#     for i in cleaned_text:\n",
    "        \n",
    "#         if i.endswith(':') == True or i == '' or i == ' ':\n",
    "#             cleaned_text.remove(i)   \n",
    "     \n",
    "#     return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_episode(raw_text):\n",
    "    \n",
    "    raw_text_no_notes = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", raw_text)\n",
    "\n",
    "    for symbol in \",.?!''\\n\":\n",
    "        raw_text_no_notes = raw_text_no_notes.replace(symbol, '').lower()\n",
    "  \n",
    "    cleaned_text = raw_text_no_notes.split(\" \")    \n",
    "    \n",
    "    for i in cleaned_text:\n",
    "        \n",
    "        if i.endswith(':') == True or i == '' or i == ' ':\n",
    "            cleaned_text.remove(i)\n",
    "            \n",
    "        i = i.replace('.', '')\n",
    "        i = i.replace('?', '')\n",
    "        i = i.replace('!', '')\n",
    "     \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'female',\n",
       " 'orgasm',\n",
       " 'is',\n",
       " 'kinda',\n",
       " 'like',\n",
       " 'the',\n",
       " 'bat',\n",
       " 'cave',\n",
       " 'a',\n",
       " 'very',\n",
       " 'few',\n",
       " 'people',\n",
       " 'know',\n",
       " 'where',\n",
       " 'it',\n",
       " 'is',\n",
       " 'and',\n",
       " 'if',\n",
       " 'youre']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in seinfeld_season_5_episodes:\n",
    "    episode_text = open_file(i)\n",
    "    cleaned_episode(episode_text)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_episodes_text_list = []\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cleaned_episode_2 = cleaned_episode(raw_text_episode_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_text_episode_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_episode_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part Two: tokenize/stemming/lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(cleaned_text):\n",
    "    return word_tokenize(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_episode_2 = tokenize(cleaned_episode_2)\n",
    "tokenized_episode_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
