{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering and Big Grams Example\n",
    "\n",
    "This notebook contains examples of NLP feature engineering, specifically Big Grams; the combination of words as features or dimensions.\n",
    "\n",
    "**Bigrams** are every pair of words in the corpus; some pairs of words that appear at least a minimum of times (usually five) hold more information than others.\n",
    "\n",
    "For example, the sentence 'I live in Santa Ana.' has the bigrams: (I, live); (live, in); (in, Santa); and (Santa, Ana). The bigram (Santa, Ana) will carry more information than (in, Santa) because it conveys the name of a place rather than a random pairing of words.\n",
    "\n",
    "**Ngrams** can be groups of n number of words or characters.\n",
    "\n",
    "You can rank any of these groups with a metric known as **Pointwise Mutual Information Score**, a statistical measure of dependency between the items within a group. The higher the score, the more information that the group conveys.\n",
    "\n",
    "*This notebook is adapted from the Learn.co leson titled \"Corpus Statistics - Lab\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from nltk.collocations import *\n",
    "from nltk import FreqDist\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_ids = gutenberg.fileids()\n",
    "file_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Clean The Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Moby Dick\n",
    "moby_dick_text = gutenberg.raw(file_ids[-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER 1\r\n",
      "\r\n",
      "Loomings.\r\n",
      "\r\n",
      "\r\n",
      "Call me Ishmael.  Some years ago--never mind how long\r\n",
      "precisely--having little or no money in my purse, and nothing\r\n",
      "particular to interest me on shore, I thought I would sail about a\r\n",
      "little and see the watery part of the world.  It is a way I have of\r\n",
      "driving off the spleen and regulating the circulation.  Whenever I\r\n",
      "find myself growing grim about the mouth; whenever it is a damp,\r\n",
      "drizzly November in my soul; whenever \n"
     ]
    }
   ],
   "source": [
    "#Remove preface\n",
    "print(moby_dick_text[21945:22400])\n",
    "moby_dick_text = moby_dick_text[21945:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize text, treat all apostrophies as one word\n",
    "\n",
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "moby_dick_tokens_raw = nltk.regexp_tokenize(moby_dick_text, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make all words lowercase\n",
    "moby_dick_tokens = [word.lower() for word in moby_dick_tokens_raw]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Exploring Text\n",
    "\n",
    "## Frequency and normalized frequency distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 14175),\n",
       " ('of', 6469),\n",
       " ('and', 6325),\n",
       " ('a', 4628),\n",
       " ('to', 4539),\n",
       " ('in', 4077),\n",
       " ('that', 2953),\n",
       " ('his', 2495),\n",
       " ('it', 2395),\n",
       " ('i', 1982),\n",
       " ('but', 1805),\n",
       " ('he', 1760),\n",
       " ('as', 1720),\n",
       " ('with', 1692),\n",
       " ('is', 1688),\n",
       " ('was', 1627),\n",
       " ('for', 1593),\n",
       " ('all', 1514),\n",
       " ('this', 1382),\n",
       " ('at', 1304),\n",
       " ('by', 1175),\n",
       " ('not', 1141),\n",
       " ('from', 1072),\n",
       " ('him', 1058),\n",
       " ('so', 1053)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Frequency Distribution to view what words are in the text\n",
    "moby_dick_freqdist = FreqDist(moby_dick_tokens)\n",
    "moby_dick_freqdist.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list += list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all stopwords from the text\n",
    "moby_dick_words_stopped = [word for word in moby_dick_tokens if word not in stopwords_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('whale', 1030),\n",
       " ('one', 896),\n",
       " ('like', 639),\n",
       " ('upon', 561),\n",
       " ('man', 474),\n",
       " ('old', 446),\n",
       " ('sea', 436),\n",
       " ('ahab', 436),\n",
       " ('ship', 429),\n",
       " ('ye', 426),\n",
       " ('would', 424),\n",
       " ('though', 382),\n",
       " ('yet', 345),\n",
       " ('head', 336),\n",
       " ('time', 332),\n",
       " ('long', 330),\n",
       " ('still', 312),\n",
       " ('captain', 306),\n",
       " ('said', 299),\n",
       " ('two', 293),\n",
       " ('great', 292),\n",
       " ('boat', 292),\n",
       " ('seemed', 282),\n",
       " ('must', 281),\n",
       " ('white', 280)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby_dick_freqdist = FreqDist(moby_dick_words_stopped)\n",
    "moby_dick_freqdist.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16939"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The total number of unique words in Moby dick after stopped words are removed is:\n",
    "len(moby_dick_freqdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word\t\t\tNormalized Frequency\n",
      "whale \t\t\t 0.009445\n",
      "one \t\t\t 0.008216\n",
      "like \t\t\t 0.00586\n",
      "upon \t\t\t 0.005144\n",
      "man \t\t\t 0.004347\n",
      "old \t\t\t 0.00409\n",
      "sea \t\t\t 0.003998\n",
      "ahab \t\t\t 0.003998\n",
      "ship \t\t\t 0.003934\n",
      "ye \t\t\t 0.003906\n",
      "would \t\t\t 0.003888\n",
      "though \t\t\t 0.003503\n",
      "yet \t\t\t 0.003164\n",
      "head \t\t\t 0.003081\n",
      "time \t\t\t 0.003044\n",
      "long \t\t\t 0.003026\n",
      "still \t\t\t 0.002861\n",
      "captain \t\t\t 0.002806\n",
      "said \t\t\t 0.002742\n",
      "two \t\t\t 0.002687\n",
      "great \t\t\t 0.002678\n",
      "boat \t\t\t 0.002678\n",
      "seemed \t\t\t 0.002586\n",
      "must \t\t\t 0.002577\n",
      "white \t\t\t 0.002568\n"
     ]
    }
   ],
   "source": [
    "#Normalize the frequency by dividing each word's frequency by the total number\n",
    "#of words in the corpus\n",
    "\n",
    "#Obtain a total word count in the corpus\n",
    "total_word_count = sum(moby_dick_freqdist.values())\n",
    "\n",
    "#View the top 25 words by normalize frequency distribution\n",
    "moby_dick_top_25 = moby_dick_freqdist.most_common(25)\n",
    "print(\"Word\\t\\t\\tNormalized Frequency\")\n",
    "for word in moby_dick_top_25:\n",
    "    normalized_frequency = word[1] / total_word_count\n",
    "    print(\"{} \\t\\t\\t {:.4}\".format(word[0], normalized_frequency))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bigrams (groups of two tokens)\n",
    "\n",
    "# Call the bigram method within NLTK\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "# Apply the Moby Dick text to the above bigram method\n",
    "moby_dick_finder = BigramCollocationFinder.from_words(moby_dick_words_stopped)\n",
    "\n",
    "# Score the bigrams\n",
    "moby_dick_scored = moby_dick_finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('sperm', 'whale'), 0.0013113250802384228),\n",
       " (('white', 'whale'), 0.0008619899128839982),\n",
       " (('moby', 'dick'), 0.0007427785419532324),\n",
       " (('captain', 'ahab'), 0.0005868867491976157),\n",
       " (('old', 'man'), 0.0005685465382851903),\n",
       " (('mast', 'head'), 0.0004309949564419991),\n",
       " (('right', 'whale'), 0.00040348464007336086),\n",
       " (('mast', 'heads'), 0.0003301237964236589),\n",
       " (('cried', 'ahab'), 0.0003026134800550206),\n",
       " (('sperm', \"whale's\"), 0.0003026134800550206),\n",
       " (('aye', 'aye'), 0.00029344337459880787),\n",
       " (('quarter', 'deck'), 0.0002842732691425951),\n",
       " (('captain', 'peleg'), 0.0002751031636863824),\n",
       " (('whale', 'ship'), 0.0002751031636863824),\n",
       " (('look', 'ye'), 0.0002567629527739569),\n",
       " (('mr', 'starbuck'), 0.0002567629527739569),\n",
       " (('one', 'hand'), 0.00024759284731774416),\n",
       " (('let', 'us'), 0.00022925263640531865),\n",
       " (('whale', 'boat'), 0.00022925263640531865),\n",
       " (('cried', 'stubb'), 0.00021091242549289317),\n",
       " (('one', 'side'), 0.00021091242549289317),\n",
       " (('every', 'one'), 0.00020174232003668043),\n",
       " (('never', 'mind'), 0.00020174232003668043),\n",
       " ((\"d'ye\", 'see'), 0.00019257221458046766),\n",
       " (('thou', 'art'), 0.00019257221458046766)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The top twenty five scored bigrams\n",
    "# Note the normalized frequencies\n",
    "moby_dick_scored[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pointwise Mutual Information Score (PMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PMI finder for bigrams\n",
    "moby_dick_pmi_finder = BigramCollocationFinder.from_words(moby_dick_words_stopped)\n",
    "\n",
    "# Apply the minimum amount of appearences a bigram must have to count\n",
    "moby_dick_pmi_finder.apply_freq_filter(5)\n",
    "\n",
    "# Calculate PMI for the remaining bigrams with five or more appearances within the text\n",
    "moby_dick_pmi_scored = moby_dick_pmi_finder.score_ngrams(bigram_measures.pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Too many bigrams, apply a bigger filter\n",
    "\n",
    "len(moby_dick_pmi_scored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the minimum amount of appearences a bigram must have to count\n",
    "moby_dick_pmi_finder.apply_freq_filter(20)\n",
    "\n",
    "# Calculate PMI for the remaining bigrams with five or more appearances within the text\n",
    "moby_dick_pmi_scored = moby_dick_pmi_finder.score_ngrams(bigram_measures.pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(moby_dick_pmi_scored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('moby', 'dick'), 10.359590813068548),\n",
       " (('mast', 'heads'), 8.540967999333212),\n",
       " (('quarter', 'deck'), 8.519527859009505),\n",
       " (('mr', 'starbuck'), 8.135514397943794),\n",
       " ((\"d'ye\", 'see'), 8.032704998385219),\n",
       " (('thou', 'art'), 7.78084951664443),\n",
       " (('captain', 'peleg'), 7.234385877826657),\n",
       " (('never', 'mind'), 7.206797850980234),\n",
       " (('aye', 'aye'), 7.1823814338670005),\n",
       " (('sperm', \"whale's\"), 6.989490718803568),\n",
       " (('mast', 'head'), 6.942705362927478),\n",
       " (('let', 'us'), 6.522304098768705),\n",
       " (('cried', 'stubb'), 6.1178816505439695),\n",
       " (('sperm', 'whale'), 6.00342990976144),\n",
       " ((\"whale's\", 'head'), 5.827739648806954),\n",
       " (('cried', 'ahab'), 5.7347156337227645),\n",
       " (('captain', 'ahab'), 5.709058076945897),\n",
       " (('white', 'whale'), 5.151507457077564),\n",
       " (('look', 'ye'), 5.141939629062065),\n",
       " (('old', 'man'), 4.999183405983786),\n",
       " (('right', 'whale'), 4.98596089614583),\n",
       " (('one', 'hand'), 3.9679173068552167),\n",
       " (('one', 'side'), 3.764336751231667),\n",
       " (('every', 'one'), 3.5729257497781326),\n",
       " (('whale', 'boat'), 3.180233253239603),\n",
       " (('whale', 'ship'), 2.888258380453866)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby_dick_pmi_scored"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
